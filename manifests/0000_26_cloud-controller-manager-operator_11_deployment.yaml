apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-cloud-controller-manager-operator
  namespace: openshift-cloud-controller-manager-operator
  annotations:
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    exclude.release.openshift.io/internal-openshift-hosted: "true"
  labels:
    k8s-app: cloud-manager-operator
spec:
  selector:
    matchLabels:
      k8s-app: cloud-manager-operator
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
      labels:
        k8s-app: cloud-manager-operator
    spec:
      priorityClassName: system-node-critical
      serviceAccountName: cluster-cloud-controller-manager
      containers:
      - name: cluster-cloud-controller-manager
        image: quay.io/openshift/origin-cluster-cloud-controller-manager-operator
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -o allexport
          if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
            source /etc/kubernetes/apiserver-url.env
          else
            URL_ONLY_KUBECONFIG=/etc/kubernetes/kubeconfig
          fi
          exec /cluster-controller-manager-operator \
          --leader-elect=true \
          --leader-elect-lease-duration=137s \
          --leader-elect-renew-deadline=107s \
          --leader-elect-retry-period=26s \
          --leader-elect-resource-namespace=openshift-cloud-controller-manager-operator \
          "--images-json=/etc/cloud-controller-manager-config/images.json"
        env:
        - name: RELEASE_VERSION
          value: "0.0.1-snapshot"
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        volumeMounts:
        - name: images
          mountPath: /etc/cloud-controller-manager-config/
        - mountPath: /etc/kubernetes
          name: host-etc-kube
          readOnly: true
      - name: config-sync-controllers
        image: quay.io/openshift/origin-cluster-cloud-controller-manager-operator
        command:
          - /bin/bash
          - -c
          - |
            #!/bin/bash
            set -o allexport
            if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
              source /etc/kubernetes/apiserver-url.env
            else
              URL_ONLY_KUBECONFIG=/etc/kubernetes/kubeconfig
            fi
            exec /config-sync-controllers \
            --leader-elect=true \
            --leader-elect-lease-duration=137s \
            --leader-elect-renew-deadline=107s \
            --leader-elect-retry-period=26s \
            --leader-elect-resource-namespace=openshift-cloud-controller-manager-operator \
            --metrics-bind-address=:9258 \
            --health-addr=127.0.0.1:9259
        ports:
        - containerPort: 9258
          name: metrics
          protocol: TCP
        - containerPort: 9259
          name: healthz
          protocol: TCP
        resources:
          requests:
            cpu: 10m
            memory: 25Mi
        volumeMounts:
          - mountPath: /etc/kubernetes
            name: host-etc-kube
            readOnly: true
      hostNetwork: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      restartPolicy: Always
      tolerations:
      - key: node.cloudprovider.kubernetes.io/uninitialized
        effect: NoSchedule
        value: "true"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120
      - key: "node.cloudprovider.kubernetes.io/uninitialized"
        operator: "Exists"
        effect: "NoSchedule"
        # CNI relies on CCM to fill in IP information on Node objects.
        # Therefore we must schedule before the CNI can mark the Node as ready.
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: images
        configMap:
          defaultMode: 420
          name: cloud-controller-manager-images
      - name: host-etc-kube
        hostPath:
          path: /etc/kubernetes
          type: Directory

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-cloud-controller-manager
  namespace: openshift-cloud-controller-manager-operator
  annotations:
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    release.openshift.io/delete: "true"
  labels:
    k8s-app: cloud-manager-operator
spec:
  selector:
    matchLabels:
      k8s-app: cloud-manager-operator
  replicas: 1
  template:
    metadata:
      annotations:
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
      labels:
        k8s-app: cloud-manager-operator
    spec:
      priorityClassName: system-node-critical
      serviceAccountName: cluster-cloud-controller-manager
      containers:
      - name: cluster-cloud-controller-manager
        image: quay.io/openshift/origin-cluster-cloud-controller-manager-operator
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -o allexport
          if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
            source /etc/kubernetes/apiserver-url.env
          fi
          exec /cluster-controller-manager-operator \
          --leader-elect \
          "--images-json=/etc/cloud-controller-manager-config/images.json"
        env:
        - name: RELEASE_VERSION
          value: "0.0.1-snapshot"
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        volumeMounts:
        - name: images
          mountPath: /etc/cloud-controller-manager-config/
        - mountPath: /etc/kubernetes
          name: host-etc-kube
          readOnly: true
      - name: config-sync-controllers
        image: quay.io/openshift/origin-cluster-cloud-controller-manager-operator
        command:
          - /bin/bash
          - -c
          - |
            #!/bin/bash
            set -o allexport
            if [[ -f /etc/kubernetes/apiserver-url.env ]]; then
              source /etc/kubernetes/apiserver-url.env
            fi
            exec /config-sync-controllers \
            --leader-elect \
            --metrics-bind-address=:8081 \
            --health-addr=:9441
        resources:
          requests:
            cpu: 10m
            memory: 25Mi
        volumeMounts:
          - mountPath: /etc/kubernetes
            name: host-etc-kube
            readOnly: true
      hostNetwork: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      restartPolicy: Always
      tolerations:
      - key: node.cloudprovider.kubernetes.io/uninitialized
        effect: NoSchedule
        value: "true"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120
      - key: "node.cloudprovider.kubernetes.io/uninitialized"
        operator: "Exists"
        effect: "NoSchedule"
        # CNI relies on CCM to fill in IP information on Node objects.
        # Therefore we must schedule before the CNI can mark the Node as ready.
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: images
        configMap:
          defaultMode: 420
          name: cloud-controller-manager-images
      - name: host-etc-kube
        hostPath:
          path: /etc/kubernetes
          type: Directory
